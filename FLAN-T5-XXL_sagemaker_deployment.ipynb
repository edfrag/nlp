{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93113bc-d83a-445b-b96d-3dc39330941d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cca7d2-3abf-4aec-a45d-dccc6412c7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker==2.116.0\" \"huggingface_hub==0.12.0\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b37d2c-3c8e-4251-af16-033307c43a96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09286c7-4aad-4ae0-82fd-1287b2e9e0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::346762710647:role/service-role/AmazonSageMaker-ExecutionRole-20221118T120164\n",
      "sagemaker bucket: sagemaker-us-east-1-346762710647\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc633fb-5cd2-46f0-a413-9bc162e11d1a",
   "metadata": {},
   "source": [
    "### Steps\n",
    "    Create FLAN-T5 XXL inference script with bnb quantization\n",
    "    Create SageMaker model.tar.gz artifact\n",
    "    Deploy the model to Amazon SageMaker\n",
    "    Run inference using the deployed model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49903379-a1aa-4301-9639-32f62eff8b7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create FLAN-T5 XXL inference script with bnb quantization\n",
    "Packing requirements.txt and inference.py in code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8af3e6-9096-4546-b3ae-9fcb8e124891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db64f654-becd-4e8d-a24d-087f4b28dc5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/requirements.txt\n",
    "accelerate==0.16.0\n",
    "transformers==4.26.0\n",
    "bitsandbytes==0.37.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8f935b-d531-49ff-b25c-04d4802a5217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "from typing import Dict, List, Any\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # load model and processor from model_dir\n",
    "    model =  AutoModelForSeq2SeqLM.from_pretrained(model_dir, device_map=\"auto\", load_in_8bit=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def predict_fn(data, model_and_tokenizer):\n",
    "    # unpack model and tokenizer\n",
    "    model, tokenizer = model_and_tokenizer\n",
    "\n",
    "    # process input\n",
    "    inputs = data.pop(\"inputs\", data)\n",
    "    parameters = data.pop(\"parameters\", None)\n",
    "\n",
    "    # preprocess\n",
    "    input_ids = tokenizer(inputs, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # pass inputs with all kwargs in data\n",
    "    if parameters is not None:\n",
    "        outputs = model.generate(input_ids, **parameters)\n",
    "    else:\n",
    "        outputs = model.generate(input_ids)\n",
    "\n",
    "    # postprocess the prediction\n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return [{\"generated_text\": prediction}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e26454-ceb3-4309-8b23-855957a1086a",
   "metadata": {},
   "source": [
    "### Create SageMaker model.tar.gz artifact\n",
    "Requires around 30GB in space. Sharded model using fp16 (quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78e9517a-591e-4b58-aa4f-feed63ae3e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e28d6ae7134116b79a163ae586b375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fetching 23 files', max=23.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db674633144b42ad88b5414ba7d6da34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)0155a/.gitattributes', max=1477.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7257f82519524aba86fbfa70dc599c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)6f60155a/config.json', max=759.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2273ac7e2ce44e682ac1a1d04259536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)2a6f60155a/README.md', max=2525.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9039c7256d4bd8bbe6ffd3d4429e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)a6f60155a/handler.py', max=1167.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9ed5da0726427e8b7506567f1dabc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00003-of-00012.bin\";', max=1929475550.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b6fb8eff7347df94eb986d040a7655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)a/createEndpoint.png', max=96271.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de217ea2c70b41d49053cef587ce83fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00001-of-00012.bin\";', max=1722882745.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d37458233441619c5d47b7062b6ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00002-of-00012.bin\";', max=1929475486.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d824fbf44b48d18533a77b101bebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00005-of-00012.bin\";', max=1929475550.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab8ffa25c154ea2ac118a34db8e7baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00004-of-00012.bin\";', max=1929475550.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955592551d864029a125c2f0e1393df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00006-of-00012.bin\";', max=1974577874.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16def7988db84c5a9fc14f48d2f115d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00007-of-00012.bin\";', max=1929485961.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c651901686584fbe89056845de8bbad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00008-of-00012.bin\";', max=1996604032.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ad3fe8a3064743aa8f14bfaaee5408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00009-of-00012.bin\";', max=1996604032.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c605bde8c4efa82f3f8701449a412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00010-of-00012.bin\";', max=1979817673.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3993938e134765896eb55dd4ba806f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00011-of-00012.bin\";', max=1979817673.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5b5d41c4ed4a06be98687da97dd0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)00012-of-00012.bin\";', max=1236336721.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba84231601d42a2a07f45ff25fd3d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)model.bin.index.json', max=50781.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07defc336d1c4367aaccfc4e7cb5b6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)55a/requirements.txt', max=52.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72bf598075848fe9a69666d4b5c5252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)cial_tokens_map.json', max=2201.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5618fd634e1e4ac9bb95ce9b05d1cac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)\"spiece.model\";', max=791656.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0599930ad4c4d97b4538eac4e0c3459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)0155a/tokenizer.json', max=2422164.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724eaa0e63834cb7b0af2ad22f1001eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)okenizer_config.json', max=2537.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "HF_MODEL_ID=\"philschmid/flan-t5-xxl-sharded-fp16\"\n",
    "# create model dir\n",
    "model_tar_dir = Path(HF_MODEL_ID.split(\"/\")[-1])\n",
    "model_tar_dir.mkdir()\n",
    "\n",
    "# setup temporary directory\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    # download snapshot\n",
    "    snapshot_dir = snapshot_download(repo_id=HF_MODEL_ID, cache_dir=tmpdir)\n",
    "    # copy snapshot to model dir\n",
    "    copy_tree(snapshot_dir, str(model_tar_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8de4edc-2f50-4810-9659-0dee94451a26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flan-t5-xxl-sharded-fp16/code/requirements.txt',\n",
       " 'flan-t5-xxl-sharded-fp16/code/inference.py']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy code/ to model dir\n",
    "copy_tree(\"code/\", str(model_tar_dir.joinpath(\"code\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf010c-275a-4944-9c8f-8303b71f1864",
   "metadata": {},
   "source": [
    "### Creating tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03920c7c-9eb2-4b2e-bc49-0cbfe8e0c9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch_model-00001-of-00012.bin\n",
      "pytorch_model-00010-of-00012.bin\n",
      "spiece.model\n",
      "createEndpoint.png\n",
      "pytorch_model-00009-of-00012.bin\n",
      "tokenizer_config.json\n",
      "pytorch_model-00005-of-00012.bin\n",
      "pytorch_model-00003-of-00012.bin\n",
      "pytorch_model-00012-of-00012.bin\n",
      "requirements.txt\n",
      "pytorch_model-00007-of-00012.bin\n",
      "config.json\n",
      "pytorch_model.bin.index.json\n",
      "pytorch_model-00011-of-00012.bin\n",
      "pytorch_model-00002-of-00012.bin\n",
      ".gitattributes\n",
      "special_tokens_map.json\n",
      "handler.py\n",
      "pytorch_model-00006-of-00012.bin\n",
      "README.md\n",
      "tokenizer.json\n",
      "pytorch_model-00004-of-00012.bin\n",
      "code\n",
      "pytorch_model-00008-of-00012.bin\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# helper to create the model.tar.gz\n",
    "def compress(tar_dir=None,output_file=\"model.tar.gz\"):\n",
    "    parent_dir=os.getcwd()\n",
    "    os.chdir(tar_dir)\n",
    "    with tarfile.open(os.path.join(parent_dir, output_file), \"w:gz\") as tar:\n",
    "        for item in os.listdir('.'):\n",
    "          print(item)\n",
    "          tar.add(item, arcname=item)\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "compress(str(model_tar_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bedd66e-a3a5-445d-8adf-b791cf79579d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Upload tarball in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99cce7f7-deba-4cb3-9125-8aad9f611aac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-us-east-1-346762710647/flan-t5-xxl/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "# upload model.tar.gz to s3\n",
    "s3_model_uri = S3Uploader.upload(local_path=\"model.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/flan-t5-xxl\")\n",
    "\n",
    "print(f\"model uploaded to: {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac9d71-c1c7-4b15-91ec-0646d681a5ee",
   "metadata": {},
   "source": [
    "### Deploy the model to Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dbc4740-6eb4-4724-b33f-aaba4935720f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,      # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.17\",  # transformers version used\n",
    "   pytorch_version=\"1.10\",       # pytorch version used\n",
    "   py_version='py38',            # python version used\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c474060-02ec-4bd6-8246-890b0c3d7231",
   "metadata": {},
   "source": [
    "### Run inference using the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4f3a963-14bd-4eaa-b5ec-6ce8a2465a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Peter stayed with Elizabeth at the hospital for 3 days.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = \"\"\"Summarize the following text:\n",
    "Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital.\n",
    "Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well.\n",
    "Therefore, Peter stayed with her at the hospital for 3 days without leaving.\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "  \"early_stopping\": True,\n",
    "  \"length_penalty\": 2.0,\n",
    "  \"max_new_tokens\": 50,\n",
    "  \"temperature\": 0,\n",
    "  \"min_length\": 10,\n",
    "  \"no_repeat_ngram_size\": 3,\n",
    "}\n",
    "\n",
    "# Run prediction\n",
    "predictor.predict({\n",
    "\t\"inputs\": payload,\n",
    "  \"parameters\" :parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8f0fc99-c395-4900-8185-3404d1c0090c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'He buys 2 cans of tennis balls, so he has 2 * 3 = 6 tennis balls. He has 5 + 6 = 11 tennis balls now.'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = \"\"\"Answer the following question step by step:\n",
    "Roger has 5 tennis balls. He buys 2 more cans of tennis balls.\n",
    "Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "  \"early_stopping\": True,\n",
    "  \"length_penalty\": 2.0,\n",
    "  \"max_new_tokens\": 50,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# Run prediction\n",
    "predictor.predict({\n",
    "\t\"inputs\": payload,\n",
    "  \"parameters\" :parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d15038-6835-4311-98b9-3ff36ad40f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The Milky Way Galaxy is a spiral galaxy that contains about 200 billion stars. The Milky Way Galaxy is the largest galaxy in the known universe. The Milky Way Galaxy contains about 200 billion stars. Therefore, the final answer is 200 billion'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = \"\"\"Answer the following question step-by-step:\n",
    "How many stars are in the milky way?\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "  \"early_stopping\": True,\n",
    "  \"length_penalty\": 2.0,\n",
    "  \"max_new_tokens\": 50,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# Run prediction\n",
    "predictor.predict({\n",
    "\t\"inputs\": payload,\n",
    "  \"parameters\" :parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7157879f-dbf8-438f-80b9-232c6a13ce64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Das Haus ist wunderbar.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = \"\"\"Answer the following question step-by-step:\n",
    "translate English to German: The house is wonderful.\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "  \"early_stopping\": True,\n",
    "  \"length_penalty\": 2.0,\n",
    "  \"max_new_tokens\": 50,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# Run prediction\n",
    "predictor.predict({\n",
    "\t\"inputs\": payload,\n",
    "  \"parameters\" :parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cfe4ab6-3d65-43c0-a693-c3976e6ad8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The first spacecraft to reach the Moon was the Soviet Luna 3 in 1959. The first spacecraft to reach the Moon was the Soviet Luna 3 in 1959. The first spacecraft to reach the Moon was the Soviet Luna 3 in 1959.'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = \"\"\"\n",
    "Write an article on space travel:\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "  \"early_stopping\": True,\n",
    "  \"length_penalty\": 2.0,\n",
    "  \"max_new_tokens\": 500,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "# Run prediction\n",
    "predictor.predict({\n",
    "\t\"inputs\": payload,\n",
    "  \"parameters\" :parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d42664-735c-4e33-b9bd-33a430d54de6",
   "metadata": {},
   "source": [
    "### Delete the model and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e4f9832-e527-4af4-a5d8-d502d5baf6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb05e0e-6c5a-4159-86d5-6a999db5342c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
